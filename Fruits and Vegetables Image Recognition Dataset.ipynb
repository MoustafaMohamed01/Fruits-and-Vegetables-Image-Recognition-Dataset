{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b1701bf-4f16-4e54-8deb-9bff28a189ab",
   "metadata": {},
   "source": [
    "# **Fruit and Vegetable Image Classification Project**\n",
    "\n",
    "This project involves building and training a **Convolutional Neural Network (CNN)** model to classify images of fruits and vegetables. The dataset is divided into training, validation, and test sets. The goal is to preprocess the images, build the CNN model, train it, evaluate its performance, and visualize the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dd0960-cc79-41c6-a0ec-33633121c473",
   "metadata": {},
   "source": [
    "Dataset: https://www.kaggle.com/datasets/kritikseth/fruit-and-vegetable-image-recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a139ad-cb25-4e79-ba3f-5a238d0e334e",
   "metadata": {},
   "source": [
    "## **Importing Necessary Libraries**\n",
    "\n",
    "We will use **TensorFlow** for building and training the model, and **Matplotlib** for visualizing the training results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680675fb-b88d-413e-b5f0-48fa49c913b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acdcb4c-67fe-4f82-aafd-8816fad05724",
   "metadata": {},
   "source": [
    "## **Loading Image Dataset for Training**\n",
    "\n",
    "We use **TensorFlow's `image_dataset_from_directory`** to load and preprocess images from a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b80891-a69b-4d27-b3e7-e8bb53278603",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"train\",\n",
    "    shuffle=True,\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32,\n",
    "    validation_split=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f845075-58b3-4ba6-beee-1d3ea7fd54df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat = data_train.class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a651388-588e-4f14-a434-64fc25a9511e",
   "metadata": {},
   "source": [
    "## **Loading Validation Dataset**\n",
    "\n",
    "We use **TensorFlow's `image_dataset_from_directory`** to load and preprocess images for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf27bf55-7a06-4503-833f-142376b5a0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"validation\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    validation_split=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b325bba-472b-44c1-ad10-94e734a002bb",
   "metadata": {},
   "source": [
    "# **Loading Test Dataset**\n",
    "\n",
    "We use **TensorFlow's `image_dataset_from_directory`** to load and preprocess images for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c27445d-3dbe-46b6-8f25-85f8d14a0b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"test\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32,\n",
    "    validation_split=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a46903-1f8c-4261-9a7e-8ff89ec72e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6),dpi=150)\n",
    "for image, labels in data_train.take(1):\n",
    "    for i in range(6):\n",
    "        plt.subplot(2,3,i+1)\n",
    "        plt.imshow(image[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(data_cat[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46de413-79bc-4436-9857-b56c72752c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdded6f-04fd-4bc4-9271-fc47e509d691",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network (CNN) Model\n",
    "\n",
    "This model is designed for image classification, particularly for datasets like fruits and vegetables. It processes images through multiple convolutional layers and dense layers to extract features and make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affdc2d4-07db-4acf-b405-d68fd88741fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73496a2-b7bb-421e-8174-7ed3a33ccceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Rescaling(1./255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09f625a-18ae-4c5f-85d1-512cb29002ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Conv2D(16, 3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92edd32f-9268-46c1-8188-f4d1aa85f9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660b3329-e431-43ef-a6df-e817852762ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a501b0-0a27-4e1f-8081-16160eeecc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4f50ac-6242-4e09-b58d-a37b48225b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f09b96-cc36-4405-ac11-b3e1b327fe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7524afaf-6a16-4d94-8be3-d719c4b9fafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(len(data_cat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4b2908-8583-4006-8c13-a9d1dc06a140",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae2f785-5cf7-4646-a5d5-2a3dcb7e0cd5",
   "metadata": {},
   "source": [
    "## **Training the CNN Model**\n",
    "\n",
    "After defining the model architecture, we train it using the **.fit()** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f5f5e1-677d-4a4f-93f0-13d80f9283ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=25\n",
    "training_results = model.fit(data_train, validation_data=data_val, epochs=epochs, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77aa3e7-7cbc-4861-9201-b97449f51344",
   "metadata": {},
   "source": [
    "## **Visualizing Model Performance**\n",
    "\n",
    "After training the CNN model, we can analyze its performance using accuracy and loss curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195a251f-c645-40d5-ba9a-66fcdd33d28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_range = range(epochs)\n",
    "plt.style.use(\"dark_background\")\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs_range, training_results.history[\"accuracy\"], label=\"Training Accuracy\")\n",
    "plt.plot(epochs_range, training_results.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs_range, training_results.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(epochs_range, training_results.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.title(\"Loss\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig(\"training_accuracy&loss.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9b12d5-5764-48cc-9944-55f8b573e747",
   "metadata": {},
   "source": [
    "## **Image Prediction and Class Probability**\n",
    "\n",
    "In this section, we load an image, preprocess it, and use the trained model to predict its class. We also calculate the probability of the predicted class and display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01729f8f-00f4-458c-9fef-263e7284ff2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = \"test/spinach/Image_4.jpg\"\n",
    "image = tf.keras.utils.load_img(image, target_size=(180, 180))\n",
    "image = tf.keras.utils.array_to_img(image)\n",
    "image = tf.expand_dims(image, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9340ca60-121b-4710-a527-a3093f571cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842b6f21-b622-43ac-86df-d973aba7cdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = tf.nn.softmax(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12155132-6e4d-4c0b-bc30-da4849dca6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Image: {} | Accuracy: {:0.2f}%\".format(data_cat[np.argmax(score)], np.max(score)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c924dec-0fa9-41ae-9c71-d35a863eec2b",
   "metadata": {},
   "source": [
    "## **Conclusion**\n",
    "\n",
    "In this project, we built and trained a Convolutional Neural Network (CNN) model to classify images of fruits and vegetables. The project workflow was as follows:\n",
    "\n",
    "1. **Dataset Preparation**:\n",
    "   - We utilized a labeled dataset of fruits and vegetables, which was split into training, validation, and test sets. \n",
    "   - The images were preprocessed by resizing them to the target size (180x180), ensuring consistency in input dimensions for the model.\n",
    "\n",
    "2. **Model Architecture**:\n",
    "   - The model was built using a Sequential API in TensorFlow with several convolutional layers followed by max-pooling layers to extract features from the images.\n",
    "   - A Flatten layer was used to convert the 2D feature maps into 1D, and dropout was applied for regularization to prevent overfitting.\n",
    "   - Finally, the output layer was a Dense layer with the number of units equal to the number of classes (fruits/vegetables), applying a softmax activation function to predict the class probabilities.\n",
    "\n",
    "3. **Training**:\n",
    "   - The model was trained using the `fit()` method on the training data for 25 epochs, with a batch size of 32. \n",
    "   - We used the validation dataset during training to monitor the modelâ€™s performance and ensure generalization.\n",
    "\n",
    "4. **Evaluation**:\n",
    "   - After training, the model's performance was evaluated based on accuracy and loss curves, showing how the model learned over time.\n",
    "   - We used metrics such as accuracy and loss to assess both training and validation performance.\n",
    "\n",
    "5. **Prediction**:\n",
    "   - The model was able to successfully predict the class of new images of fruits and vegetables by converting them into the appropriate format and using the trained model to obtain class probabilities.\n",
    "\n",
    "\n",
    "### **Key Takeaways**:\n",
    "- This project highlights the power of deep learning, particularly Convolutional Neural Networks (CNNs), in image classification tasks.\n",
    "- The model was able to effectively classify various types of fruits and vegetables with high accuracy.\n",
    "- Future improvements could involve experimenting with more advanced techniques like data augmentation or fine-tuning the model for better accuracy.\n",
    "- This project provides a foundational understanding of how image classification works and can be applied to real-world scenarios in fields like agriculture, food recognition, and even health and safety applications.\n",
    "\n",
    "Overall, this project demonstrates the process of developing a robust image classification model using TensorFlow and Keras, from data preprocessing to model evaluation and deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f0f82b-a519-4777-84e8-db08a80133bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
